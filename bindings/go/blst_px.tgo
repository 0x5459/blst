//
// Serialization/Deserialization.
//

// P1 Serdes
func (p1 *P1Affine) Serialize() []byte {
    var out [BLST_P1_SERIALIZE_BYTES]byte
    C.blst_p1_affine_serialize((*C.byte)(&out[0]), p1)
    return out[:]
}

func (p1 *P1Affine) Deserialize(in []byte) *P1Affine {
    if len(in) != BLST_P1_SERIALIZE_BYTES {
        return nil
    }
    if C.blst_p1_deserialize(p1, (*C.byte)(&in[0])) != C.BLST_SUCCESS {
        return nil
    }
    return p1
}
func (p1 *P1Affine) Compress() []byte {
    var out [BLST_P1_COMPRESS_BYTES]byte
    C.blst_p1_affine_compress((*C.byte)(&out[0]), p1)
    return out[:]
}

func (p1 *P1Affine) Uncompress(in []byte) *P1Affine {
    if len(in) != BLST_P1_COMPRESS_BYTES {
        return nil
    }
    if C.blst_p1_uncompress(p1, (*C.byte)(&in[0])) != C.BLST_SUCCESS {
        return nil
    }
    return p1
}

func (p1 *P1Affine) InG1() bool {
  return bool(C.blst_p1_affine_in_g1(p1))
}

func (dummy *P1Affine) BatchUncompress(in [][]byte) []*P1Affine {
    // Allocate space for all of the resulting points. Later we'll save pointers
    // and return those so that the result could be used in other functions,
    // such as MultipleAggregateVerify.
    n := len(in)
    points := make([]P1Affine, n)
    pointsPtrs := make([]*P1Affine, n)

    numCores := runtime.GOMAXPROCS(0)
    numThreads := maxProcs
    if numThreads > numCores {
        numThreads = numCores
    }
    if numThreads > n {
        numThreads = n
    }
    // Each thread will determine next message to process by atomically
    // incrementing curItem, process corresponding point, and
    // repeat until n is exceeded. Each thread will send a result (true for
    // success, false for failure) into the channel when complete.
    resCh := make(chan bool, numThreads)
    valid := int32(1)
    curItem := uint32(0)
    for tid := 0; tid < numThreads; tid++ {
        go func() {
            for atomic.LoadInt32(&valid) > 0 {
                // Get a work item
                work := atomic.AddUint32(&curItem, 1) - 1
                if work >= uint32(n) {
                    break
                }
                if points[work].Uncompress(in[work]) == nil {
                    atomic.StoreInt32(&valid, 0)
                    break
                }
                pointsPtrs[work] = &points[work]
            }
            if atomic.LoadInt32(&valid) > 0 {
                resCh <- true
            } else {
                resCh <- false
            }
        }()
    }

    // Collect the threads
    result := true
    for i := 0; i < numThreads; i++ {
        if ! <-resCh {
            result = false
        }
    }
    if atomic.LoadInt32(&valid) == 0 || result == false {
        return nil
    }
    return pointsPtrs
}

func (p1 *P1) Serialize() []byte {
    var out [BLST_P1_SERIALIZE_BYTES]byte
    C.blst_p1_serialize((*C.byte)(&out[0]), p1)
    return out[:]
}
func (p1 *P1) Compress() []byte {
    var out [BLST_P1_COMPRESS_BYTES]byte
    C.blst_p1_compress((*C.byte)(&out[0]), p1)
    return out[:]
}

//
// Affine
//

func (p *P1) ToAffine() *P1Affine {
    var pa P1Affine
    C.blst_p1_to_affine(&pa, p)
    return &pa
}

func (p *P1) FromAffine(pa *P1Affine) {
    C.blst_p1_from_affine(p, pa)
}

//
// Hash
//
func HashToG1(msg []byte, dst []byte,
        optional ...[]byte) *P1 { // aug
    var q P1

    // Handle zero length message
    var msgC *C.byte
    if len(msg) > 0 {
        msgC = (*C.byte)(&msg[0])
    }

    var dstC *C.byte
    if len(dst) > 0 {
        dstC = (*C.byte)(&dst[0])
    }

    var aug []byte
    var augC *C.byte
    if len(optional) > 0 {
        aug = optional[0]
        if len(aug) > 0 {
            augC = (*C.byte)(&aug[0])
        }
    }

    C.blst_hash_to_g1(&q, msgC, C.size_t(len(msg)),
                          dstC, C.size_t(len(dst)),
                          augC, C.size_t(len(aug)))
    return &q
}

func EncodeToG1(msg []byte, dst []byte,
        optional ...[]byte) *P1 { // aug
    var q P1

    // Handle zero length message
    var msgC *C.byte
    if len(msg) > 0 {
        msgC = (*C.byte)(&msg[0])
    }

    var dstC *C.byte
    if len(dst) > 0 {
        dstC = (*C.byte)(&dst[0])
    }

    var aug []byte
    var augC *C.byte
    if len(optional) > 0 {
        aug = optional[0]
        if len(aug) > 0 {
            augC = (*C.byte)(&aug[0])
        }
    }

    C.blst_encode_to_g1(&q, msgC, C.size_t(len(msg)),
                            dstC, C.size_t(len(dst)),
                            augC, C.size_t(len(aug)))
    return &q
}

//
// Multi-point/scalar operations
//

func P1sToAffine(points []*P1, optional ...int) P1Affines {
    var npoints int
    if len(optional) > 0 {
        npoints = optional[0]
    } else {
        npoints = len(points)
    }
    ret := make([]P1Affine, npoints)
    p := uintptr(unsafe.Pointer(&points[0]))
    C.blst_p1s_to_affine(&ret[0], (**P1)(unsafe.Pointer(p)), C.size_t(npoints))
    return ret
}

func (points P1s) ToAffine() P1Affines {
    return P1sToAffine([]*P1{&points[0], nil}, len(points))
}

//
// Batch addition
//

func P1AffinesAdd(points []*P1Affine, optional ...int) *P1 {
    var npoints int
    if len(optional) > 0 {
        npoints = optional[0]
    } else {
        npoints = len(points)
    }
    var ret P1
    p := uintptr(unsafe.Pointer(&points[0]))
    C.blst_p1s_add(&ret, (**P1Affine)(unsafe.Pointer(p)), C.size_t(npoints))
    return &ret
}

func (points P1Affines) Add() *P1 {
    return P1AffinesAdd([]*P1Affine{&points[0], nil}, len(points))
}

func (points P1s) Add() *P1 {
    return points.ToAffine().Add()
}

//
// Multi-scalar multiplication
//

func P1AffinesMult(pointsIf interface{}, scalarsIf interface{}, nbits int) *P1 {
    var points []*P1Affine
    var npoints int
    switch val := pointsIf.(type) {
    case []*P1Affine:
        points = val
        npoints = len(val)
    case []P1Affine:
        points = []*P1Affine{&val[0], nil}
        npoints = len(val)
    case P1Affines:
        points = []*P1Affine{&val[0], nil}
        npoints = len(val)
    default:
        panic(fmt.Sprintf("unsupported type %T", val))
    }

    nbytes := (nbits+7)/8
    var scalars []*C.byte
    switch val := scalarsIf.(type) {
    case []byte:
        if len(val) < npoints*nbytes {
            return nil
        }
        scalars = []*C.byte{(*C.byte)(&val[0]), nil}
    case [][]byte:
        if len(val) < npoints {
            return nil
        }
        scalars = make([]*C.byte, npoints)
        for i := range scalars {
            scalars[i] = (*C.byte)(&val[i][0])
        }
    case []Scalar:
        if len(val) < npoints {
            return nil
        }
        if (nbits > 248) {
            scalars = []*C.byte{&val[0].b[0], nil}
        } else {
            scalars = make([]*C.byte, npoints)
            for i := range scalars {
                scalars[i] = &val[i].b[0]
            }
        }
    case []*Scalar:
        if len(val) < npoints {
            return nil
        }
        scalars = make([]*C.byte, npoints)
        for i := range scalars {
            scalars[i] = &val[i].b[0]
        }
    default:
        panic(fmt.Sprintf("unsupported type %T",val))
    }

    sz := int(C.blst_p1s_mult_pippenger_scratch_sizeof(C.size_t(npoints))) / 8
    scratch := make([]uint64, sz)

    var ret P1
    p := uintptr(unsafe.Pointer(&points[0]))
    s := uintptr(unsafe.Pointer(&scalars[0]))
    C.blst_p1s_mult_pippenger(&ret, (**P1Affine)(unsafe.Pointer(p)),
                              C.size_t(npoints),
                              (**C.byte)(unsafe.Pointer(s)),
                              C.size_t(nbits), (*C.limb_t)(&scratch[0]))
        return &ret
}

func (points P1Affines) Mult(scalarsIf interface{}, nbits int) *P1 {
    return P1AffinesMult(points, scalarsIf, nbits)
}

func (points P1s) Mult(scalarsIf interface{}, nbits int) *P1 {
    return points.ToAffine().Mult(scalarsIf, nbits)
}
